{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "import scipy as sp\n",
    "from tqdm import tqdm, trange\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "\n",
    "import keras\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, LeakyReLU, Dropout, Embedding, Concatenate\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.convolutional import Conv3D, Deconv3D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from keras.utils import multi_gpu_model\n",
    "import skimage.transform as skt\n",
    "\n",
    "from keras.utils import generic_utils as keras_generic_utils\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def load_nifti(file_path, mask=None, z_factor=None, remove_nan=False):\n",
    "    \"\"\"Load a 3D array from a NIFTI file.\"\"\"\n",
    "    img = nib.load(file_path)\n",
    "    struct_arr = np.array(img.get_fdata())\n",
    "\n",
    "    if remove_nan:\n",
    "        struct_arr = np.nan_to_num(struct_arr)\n",
    "    if mask is not None:\n",
    "        struct_arr *= mask\n",
    "    if z_factor is not None:\n",
    "        struct_arr = np.around(zoom(struct_arr, z_factor), 0)\n",
    "\n",
    "    return struct_arr\n",
    "\n",
    "\n",
    "def save_nifti(file_path, struct_arr):\n",
    "    \"\"\"Save a 3D array to a NIFTI file.\"\"\"\n",
    "    img = nib.Nifti1Image(struct_arr, np.eye(4))\n",
    "    nib.save(img, file_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Nifti Functions\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]\n",
      "100%|██████████| 299/299 [00:00<?, ?it/s]A\n",
      "\n",
      "100%|██████████| 626/626 [00:00<00:00, 208814.56it/s]\n",
      "\n",
      "100%|██████████| 299/299 [00:00<?, ?it/s]A\n",
      "\n",
      "100%|██████████| 714/714 [00:00<00:00, 119074.87it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 45.45it/s]\n",
      "100%|██████████| 1170/1170 [00:00<00:00, 5651.80it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def prepare_data(use_smooth = False, running_on_server = False):\n",
    "    root_dir = 'C:/Users/Eshan/Google Drive UALBERTA/Data/' if not running_on_server else '/mnt/hdd1/lxc-hdd1/tahjid/PD Data/'\n",
    "    patient_list, patient_numbers, dataset = [], [], []\n",
    "    label_map = dict(Control=0, PD=1)\n",
    "    type_map = dict(FullScan=0, GrayMatter=1, WhiteMatter=2)\n",
    "    full_scan_path = root_dir + 'FinalData/'\n",
    "    wmgmpath = root_dir + 'FinalDataWMGM/' if not use_smooth else root_dir + 'FinalDataWMGMSmooth/'\n",
    "    prefix = 'mwp' if not use_smooth else 'smwp'\n",
    "    ext = '.nii'\n",
    "    for i in tqdm(['Control', 'PD']):\n",
    "        path = full_scan_path + i + '/'\n",
    "        listOfFiles = [f for f in os.listdir(path) if f.endswith(ext)]\n",
    "        for file in tqdm(listOfFiles):\n",
    "            patient_numbers.append(file[:4])\n",
    "        path = wmgmpath + i + '/'\n",
    "        listOfFiles = [f for f in os.listdir(path) if f.endswith(ext)]\n",
    "        for file in tqdm(listOfFiles):\n",
    "            filename = file[4:8] if not use_smooth else file[5:9]\n",
    "            if filename not in patient_numbers:\n",
    "                continue\n",
    "            if not use_smooth:\n",
    "                patient_list.append([i, file[4:8]])\n",
    "            else:\n",
    "                patient_list.append([i, file[5:9]])\n",
    "\n",
    "    for i in tqdm(patient_list):\n",
    "        path = full_scan_path + i[0] + '/'\n",
    "        patientIdVal = i[1]\n",
    "        fullScanvalue = os.path.join(path + i[1] + ext)\n",
    "        path = wmgmpath + i[0] + '/'\n",
    "        gmval = os.path.join(path + prefix + str(type_map['GrayMatter']) + i[1] + ext)\n",
    "        wmval = os.path.join(path + prefix + str(type_map['WhiteMatter']) + i[1] + ext)\n",
    "        labelval = label_map[i[0]]\n",
    "        dataset.append([patientIdVal,fullScanvalue, gmval, wmval, labelval])\n",
    "    return np.array(dataset)\n",
    "dataset = prepare_data()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "\n",
    "def normalize(input):\n",
    "    \"\"\"Normalize inputs between -1 and +1\"\"\"\n",
    "    normd = 2*(input-input.min())/(input.max()-input.min())-1\n",
    "    return normd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, data, labels, batch_size = 2, dim1 = (91,109,91), dim2 = (242, 145, 121) , n_channels=1,\n",
    "                 n_classes = 2, shuffle = True,\n",
    "                 target_size = (256/4, 256/2, 256/2), resize = True, normalize = True):\n",
    "        'Initialization'\n",
    "        # self.dim1 = dim1\n",
    "        self.dim = dim2\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = list(labels)\n",
    "        self.data = data\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.list_IDs = list(data[:,:1])\n",
    "        self.target_size = tuple(int(a) for a in target_size)\n",
    "        self.resize = resize\n",
    "        self.normalize = normalize\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __numbatches__(self):\n",
    "        return int(np.floor(len(self.list_IDs) / self.__len__()))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(indexes)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, indexes):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        gmwm = np.empty((self.batch_size, self.n_channels,  self.target_size[1], self.target_size[1], self.target_size[2]))\n",
    "        y = np.empty((self.batch_size), dtype=int)\n",
    "\n",
    "        # Generate data\n",
    "        for i, count in enumerate(indexes):\n",
    "            val = self.data[count]\n",
    "            graymatter = load_nifti(val[2])\n",
    "            whitematter = load_nifti(val[3])\n",
    "\n",
    "            graymatter = graymatter.astype(np.float64)\n",
    "            whitematter = whitematter.astype(np.float64)\n",
    "\n",
    "            if self.normalize:\n",
    "                graymatter = normalize(graymatter)\n",
    "                whitematter = normalize(whitematter)\n",
    "\n",
    "            if self.resize:\n",
    "                graymatter = skt.resize(graymatter, self.target_size, mode = 'constant')\n",
    "                whitematter = skt.resize(whitematter, self.target_size, mode = 'constant')\n",
    "\n",
    "            print(graymatter.shape)\n",
    "            print(whitematter.shape)\n",
    "            gmwm[i,] = np.concatenate((graymatter, whitematter))[np.newaxis, ...]\n",
    "\n",
    "            # Store class\n",
    "            y[i] = self.labels[i]\n",
    "\n",
    "        return gmwm, y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "X = dataset[:,:4]\n",
    "y = dataset[:,4:]\n",
    "d = DataGenerator(X, y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 128, 128)\n",
      "(64, 128, 128)\n",
      "(64, 128, 128)\n",
      "(64, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "a = d.__getitem__(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "(2, 1, 128, 128, 128)"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "(64, 128, 128)"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}